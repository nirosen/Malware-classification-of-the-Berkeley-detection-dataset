import torch.nn as nn
import torch.nn.utils as utils
import torch.nn.functional as F

# from .attention import SCNNAttention
from utils.logger import *


log = get_logger(__name__)


class SCNN(nn.Module):
    def __init__(self, categories_count, embedding_size, hidden_size, classes_count, normalize=False):
        super(SCNN, self).__init__()
        # self.log = log
        #
        # self.categories_count = categories_count
        # self.embedding_size = embedding_size
        # self.hidden_size = hidden_size
        # self.classes_count = classes_count
        #
        # self.embedding = nn.Embedding(categories_count, embedding_size, 0)
        # self.gru = nn.GRU(embedding_size, hidden_size)  # Dan also added MultiHeadAtt
        # self.normalize = nn.BatchNorm1d(hidden_size)
        # self.linear = nn.Linear(hidden_size, classes_count)
        #
        self.retry = 3

        self.linear2 = nn.Linear(5922, 2) # TODO: make TFIDF vector size generic!

    def forward(self, input_sequence):
        for try_count in range(self.retry):
            try:
                # embedding = self.embedding(input_sequence.data.long())
                # #embedding = self.embedding(input_sequence.data)
                # embedded = utils.rnn.PackedSequence(embedding, input_sequence.batch_sizes)
                # output, hn = self.gru(embedded)
                # output = hn.squeeze()
                # predicted_log_probabilities = F.log_softmax(self.linear(output), dim=1)

                #embedding = self.embedding(input_sequence.data.long())
                #embedding_new = self.embedding_new(input_sequence.data.long())
                #ret_new = self.fc_new(embedding_new)

                predicted_log_probabilities2 = self.linear2(input_sequence.data.float())
                predicted_log_probabilities2_softmax = F.log_softmax(predicted_log_probabilities2, dim=1)
                #predicted_log_probabilities2_logsigmoid = F.logsigmoid(predicted_log_probabilities2)
                return predicted_log_probabilities2_softmax
            except Exception as ex:
                self.log.error(ex)
                self.log.error(f"Failed to forward input_sequence of shape: {input_sequence.shape}.", ex)
                continue


                # output, hn = self.lstm(embedded)
                #normalized_output = self.normalize(output)
                #predicted_log_probabilities = F.log_softmax(self.linear(normalized_output), dim=1)
