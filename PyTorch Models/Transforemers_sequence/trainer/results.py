from analysis import visualization
import os

def save_result_to_file(file_name, headers, result_values):
    with open(os.path.join('output', file_name), 'w') as file_handle:
        iteration = 0
        file_handle.write("{0}\n".format(headers))
        for loss_value in result_values:
            file_handle.write("{0},{1}\n".format(iteration, loss_value))
            iteration += 1


def save_train_result():
    # output the train batch loss values to a file
    save_result_to_file(__train_epoch_mean_loss_file__, "Epoch,Mean_Loss", train_epoch_mean_loss_values)

    # output the validation epoch loss values to a file
    save_result_to_file(__valid_epoch_loss_file__, "Epoch,Loss", valid_epoch_loss_values)

    # output the validation epoch metric values to a file
    save_result_to_file(__valid_epoch_metrics_file__, "Epoch,Precision,Recall,AUC",
                        [",".join([str(value) for value in valid_metrics]) for valid_metrics in valid_epoch_metric_values])

    # 1 - plot training loss
    visualization.plot_simple_loss_graph(train_epoch_mean_loss_values, "Epoch Iterations", "Negative Log Likelihood Loss", "Training Loss")

    # 1 - plot validation loss
    visualization.plot_simple_loss_graph(valid_epoch_loss_values, "Epoch Iterations", "Negative Log Likelihood Loss", "Validation Loss")

    # 2 - plot validation metrics
    visualization.plot_metrics_graph(valid_epoch_metric_values, "Epoch Iterations", "Metric Value", "Validation Metric Result")


def save_test_results(test_fpr, test_tpr, test_auc, test_recall, test_precision):
    # 3 - plot test ROC curve
    visualization.plot_roc_curve(test_fpr, test_tpr, test_auc, "Test Receiver Operating Characteristic Curve")

    # 3 - plot test Recall Precision curve
    visualization.plot_precision_recall_curve(test_recall, test_precision, "Test Precision Recall Curve")
